{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MavelSterling/Lab-curso-NLP/blob/main/Sesion2/2-nlp-with-lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4efb44e"
      },
      "source": [
        "# NLP con Long-Short Term Memory (LSTM)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MavelSterling/Lab-curso-NLP/blob/main/Sesion2/2-nlp-with-lstm-personal.ipynb)\n",
        "\n",
        "En este notebook implementaremos un clasificador de texto en espaÃ±ol utilizando la arquitectura de red LSTM.\n",
        "La idea es tener un punto de referencia para comparar mÃ¡s adelante con modelos basados en transformers.\n",
        "A diferencia del notebook guÃ­a, aquÃ­ se utilizarÃ¡ un dataset distinto para observar los resultados y comentar los hallazgos.\n",
        "\n",
        "Utilizaremos utilidades de Hugging Face (datasets) para descargar los datos y construiremos un tokenizador simple para entrenar un modelo LSTM con PyTorch/Lightning.\n",
        "\n",
        "#### Referencias\n",
        "- Dataset: https://huggingface.co/datasets/mteb/SpanishSentimentClassification\n",
        "- [Long Short-Term Memory](https://www.researchgate.net/publication/13853244_Long_Short-Term_Memory#fullTextFileContent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "936855e4",
        "outputId": "d9f1b1e2-1e1f-49cb-9a1c-965b38b28edd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2439/2684744068.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  import pkg_resources\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m853.6/853.6 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m857.3/857.3 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import pkg_resources\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "installed_packages = [package.key for package in pkg_resources.working_set]\n",
        "IN_COLAB = 'google-colab' in installed_packages\n",
        "\n",
        "!test '{IN_COLAB}' = 'True' && pip -q install lightning datasets torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6df40a98"
      },
      "source": [
        "### EDA\n",
        "El dataset seleccionado contiene textos en espaÃ±ol etiquetados para clasificaciÃ³n de sentimiento.\n",
        "EstÃ¡ disponible en el Hugging Face Hub y puede descargarse fÃ¡cilmente con la librerÃ­a datasets.\n",
        "\n",
        "La intenciÃ³n en esta secciÃ³n es:\n",
        "- Cargar los splits (train/validation/test)\n",
        "- Revisar su estructura\n",
        "- Observar algunos registros\n",
        "- Analizar de forma general las longitudes de los textos, para guiar decisiones posteriores (por ejemplo max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484,
          "referenced_widgets": [
            "50cdeb9b834f452dbb1517a4ace73181",
            "2350353c09ab4d2bbc9daf0a9a248444",
            "3752e552b9ff4091b7fcfa7735b4ff46",
            "8c82456fae694e1bbaadfd9799e58358",
            "a19e3f22c0be42968c6983a52fda29a8",
            "a46351c2451a4b83a0d1d6dac5835fc2",
            "e3de775137af457d87df86cfa941a5bc",
            "97e4c625cd6d441aa2a042d76df46223",
            "3c8164144504490fa790233e22a5efdd",
            "2ddcc57e6e804b96855701fcb3d3987a",
            "d0e6b544d8064515b8def68564b2142b",
            "082d1bee1262439f862f53b06be70daf",
            "eaa6d9f8ab5d4a3f9fdc4b5527785ada",
            "ec7cf8bb53e1488faa11b14a4db9f637",
            "263b5dc11fcb42e4a5ff708b6c93a403",
            "fe596db436464bcd8cb4183d8e836773",
            "d757b7f7544f483a9083b1591fdaafe0",
            "388e1bdb645c4bfe99a9336e447e943b",
            "6d6df6e5690341ce97b282a0e62d4f32",
            "bc9278cb56454cadb099e34c579475f5",
            "b03f87e985cb43b99f6d4c796a0d8419",
            "a25f2797586f4226b648e05a0ba204e1",
            "af04720b3f9b470b9eef5c1920e96a1f",
            "f09329247a3e49b78b1c3c4274d47f47",
            "92eee52f291a42428f084e05426a0d6d",
            "3df9d457d9594c5396ce394b302b60b9",
            "89aaeb778e52477b9aea3f7a22f7735c",
            "17e434766d67437898f62e417dad4ba8",
            "86a5880c38124f05b570c763baf3ef04",
            "3a2c8e73d49f4bcd81b0c2f2255aae5e",
            "8dbbb233a4fc433faea9806526c0bfae",
            "067cc3a9ffa14d7dbed55917e8cffb68",
            "b788aaf1c4f6465f81a5b172ebdd5ffc",
            "cd2275c70d15474eb202c132698c086c",
            "9b2a710ca6a94812bc7faf2c7fca6ef7",
            "cd44330816a14906a70dfd5f7ca5c9f1",
            "b31d671a90794c8aacec0f26c867cc57",
            "840eef9c376840e1acfbfdd386962876",
            "4bd145d370124bfd9b21b614ba3d0cab",
            "7de31764934a41e8acd126f3dbae4908",
            "3e26373d60b24b0c9ccda396f22d99df",
            "043f5ee5ec094d54bdf73c48e036d920",
            "fc1b646e8adb41cfa88b41f8ef604600",
            "63a8a21bcd0549e2927800c3d3b5c966",
            "c8bbafc1ef8147c0aa7671807aca3f8b",
            "89ac15e2860c4890881134b7ae2b3114",
            "dd26c7d996054d90a2bd39390a615b57",
            "a3a135306bfa4b53a755eeebb8180f2d",
            "b5eb0b7b43d048a7906178188ceaa20e",
            "d63a8b2c069f4e7d9447b4919bf0d977",
            "c8b109570f284d47bf496ceb1267ee15",
            "1127e79fa311410b9b022d883658e528",
            "2c3f9893f6e64aa89b91bf28b1dfb845",
            "a7d4ec55562c4b72a9a376a3d0b512f2",
            "7c18bac3633042f9844afeea17b10ac1",
            "5fcbf791398c40cd941f653345b8a539",
            "65aa6fea445a4bf7aa436466b1fe4eab",
            "9ce74284d9ad457d8b8b19378e24d330",
            "9494818d594d452a90eb0492657e115b",
            "f13114c97882421f8cd373c60f8a2782",
            "81648c3da5dd412bbecc389f9acff809",
            "81cc7ee61fe14aa6bddf2bb2fa980440",
            "b546a8438ebf4925a0c42f063d72dd5f",
            "620af699ac7444b699786c51abd5e77d",
            "c6797f958d554066b3726316b2f9d03e",
            "fba0d69223c14841a1d4bf99e22dd4a9",
            "806498f59fe84e23acd19c10ec51faef",
            "01c0988adebe44e2baef6e984a8314b9",
            "417db9bb233948508fd2c6e4cb176942",
            "accb096d0c4541c0af15fe46a698d8bc",
            "a6124a0bb00143f585111cbc05d9c099",
            "77c59e6024f84fd9ad56ae473c4aa72d",
            "86c11d942fff4787aeefa24653e25673",
            "6e806dd6a55a455286aa2bf4ad2aac9e",
            "64a1e2138df149139c9e3ad375386c65",
            "eedd76ef22624a90b5b00c1b17deb950",
            "6d04cb01fc344c9e9cf3899bb6fd1fcf"
          ]
        },
        "id": "02b91601",
        "outputId": "40ff6dfb-ab53-4de5-f69f-50c4f230175d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50cdeb9b834f452dbb1517a4ace73181"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00001.parquet:   0%|          | 0.00/59.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "082d1bee1262439f862f53b06be70daf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/validation-00000-of-00001.parquet:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af04720b3f9b470b9eef5c1920e96a1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/test-00000-of-00001.parquet:   0%|          | 0.00/18.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd2275c70d15474eb202c132698c086c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1029 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8bbafc1ef8147c0aa7671807aca3f8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/147 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fcbf791398c40cd941f653345b8a539"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/296 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "806498f59fe84e23acd19c10ec51faef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 1029\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 147\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 296\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "\n",
        "dataset = load_dataset(\"mteb/SpanishSentimentClassification\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14abea7d",
        "outputId": "be91c149-8f72-43bb-f853-aa1f18ea4a2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': 'EstÃ¡ situado en el centro de la ciudad , con todo lo mÃ¡s turÃ­stico a tu alrededor ( El Pilar , por ejemplo ) , y sitios para tomar algo .',\n",
              " 'label': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_lengths = [len(row['text']) for row in dataset[\"train\"]]\n",
        "\n",
        "print(f\"Texto mÃ¡s corto: {min(text_lengths)}\")\n",
        "print(f\"Texto mÃ¡s largo: {max(text_lengths)}\")\n",
        "print(f\"Longitud promedio: {sum(text_lengths) / len(text_lengths)}\")"
      ],
      "metadata": {
        "id": "MOrp-QPv4BYE",
        "outputId": "c450d313-f4ad-420b-db40-bd66d8ad27a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto mÃ¡s corto: 5\n",
            "Texto mÃ¡s largo: 608\n",
            "Longitud promedio: 84.85714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6642761",
        "outputId": "cfe765dc-0142-4185-c796-c7b47ff34a88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({1: 851, 0: 178})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "label_counts = Counter([row[\"label\"] for row in dataset[\"train\"]])\n",
        "label_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir de la inspecciÃ³n del dataset, se observa lo siguiente:\n",
        "\n",
        "El conjunto de entrenamiento no es muy grande (1029 ejemplos).TambiÃ©n se observa que los textos, en general, son relativamente cortos, aunque existen algunos casos mÃ¡s extensos.\n",
        "Finalmente, se detecta un desbalance entre clases, ya que la clase 1 aparece con mucha mayor frecuencia que la clase 0.\n",
        "Este hallazgo serÃ¡ importante al momento de interpretar las mÃ©tricas del modelo, ya que una buena exactitud no necesariamente implicarÃ¡ un buen desempeÃ±o sobre la clase minoritaria."
      ],
      "metadata": {
        "id": "kJhJIeD0I5XG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19905224"
      },
      "source": [
        "## Definiendo el Tokenizer\n",
        "\n",
        "Dado que el objetivo es entender el flujo completo de una soluciÃ³n con LSTM, en lugar de usar un tokenizador complejo, se utilizarÃ¡ una tokenizaciÃ³n bÃ¡sica a nivel de palabras. Esto permitirÃ¡:\n",
        "\n",
        "- Separar los textos en tokens\n",
        "- Construir un vocabulario propio a partir del conjunto de entrenamiento\n",
        "- Convertir cada texto en una secuencia de ids numÃ©ricos\n",
        "- Preparar las entradas para la red LSTM\n",
        "\n",
        "Antes de construir el vocabulario, conviene observar cuÃ¡ntos tokens tienden a tener los textos, ya que esto ayudarÃ¡ a definir una longitud mÃ¡xima de secuencia mÃ¡s razonable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "18d840a7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def simple_tokenizer(text):\n",
        "    text = text.lower().strip()\n",
        "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text, re.UNICODE)\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_lengths = [len(simple_tokenizer(row[\"text\"])) for row in dataset[\"train\"]]\n",
        "\n",
        "print(f\"Secuencia mÃ¡s corta (tokens): {min(token_lengths)}\")\n",
        "print(f\"Secuencia mÃ¡s larga (tokens): {max(token_lengths)}\")\n",
        "print(f\"Longitud promedio (tokens): {sum(token_lengths) / len(token_lengths)}\")"
      ],
      "metadata": {
        "id": "Hd8zK4FNJ61J",
        "outputId": "f3e83fad-a441-4738-ca46-e943ac4a0e3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Secuencia mÃ¡s corta (tokens): 1\n",
            "Secuencia mÃ¡s larga (tokens): 127\n",
            "Longitud promedio (tokens): 16.559766763848398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9f037f43",
        "outputId": "35c1f5fc-0ea6-41fb-9bfd-4f990964eb50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P50: 12.0\n",
            "P75: 22.0\n",
            "P90: 35.0\n",
            "P95: 45.0\n",
            "P99: 74.72000000000003\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "print(f\"P50: {np.percentile(token_lengths, 50)}\")\n",
        "print(f\"P75: {np.percentile(token_lengths, 75)}\")\n",
        "print(f\"P90: {np.percentile(token_lengths, 90)}\")\n",
        "print(f\"P95: {np.percentile(token_lengths, 95)}\")\n",
        "print(f\"P99: {np.percentile(token_lengths, 99)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_tokenizer(dataset[\"train\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "f5J0HTWxKJ9F",
        "outputId": "448b7f53-89dc-45f1-995d-0263c70d9420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['estÃ¡',\n",
              " 'situado',\n",
              " 'en',\n",
              " 'el',\n",
              " 'centro',\n",
              " 'de',\n",
              " 'la',\n",
              " 'ciudad',\n",
              " ',',\n",
              " 'con',\n",
              " 'todo',\n",
              " 'lo',\n",
              " 'mÃ¡s',\n",
              " 'turÃ­stico',\n",
              " 'a',\n",
              " 'tu',\n",
              " 'alrededor',\n",
              " '(',\n",
              " 'el',\n",
              " 'pilar',\n",
              " ',',\n",
              " 'por',\n",
              " 'ejemplo',\n",
              " ')',\n",
              " ',',\n",
              " 'y',\n",
              " 'sitios',\n",
              " 'para',\n",
              " 'tomar',\n",
              " 'algo',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fa0668c"
      },
      "source": [
        "Con base en la exploraciÃ³n anterior, definiremos una longitud mÃ¡xima de secuencia de 48 tokens.\n",
        "\n",
        "Esta decisiÃ³n busca equilibrar dos cosas:\n",
        "\n",
        "- Cubrir la mayorÃ­a de ejemplos sin recortar demasiado texto Ãºtil\n",
        "- Evitar un exceso de padding en textos cortos, que son la mayorÃ­a del dataset\n",
        "\n",
        "Dado que el percentil 95 se encuentra en 45 tokens, usar 48 permite capturar un poco mÃ¡s de contexto sin incrementar innecesariamente el costo computacional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "e4e68c73",
        "outputId": "1d97bd19-a50f-4d5e-c146-c82f9c7a8354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "max_len = 48\n",
        "max_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "008e6557"
      },
      "source": [
        "Construiremos ahora el vocabulario a partir del conjunto de entrenamiento.\n",
        "\n",
        "Para ello:\n",
        "- Se tokenizarÃ¡n todos los textos de entrenamiento\n",
        "- Se contarÃ¡ la frecuencia de cada token\n",
        "- Se reservarÃ¡n dos tokens especiales:\n",
        "  - [PAD] para relleno\n",
        "  - [UNK] para tokens desconocidos\n",
        "\n",
        "Como este dataset es pequeÃ±o, no es necesario usar un vocabulario extremadamente grande. Se conservarÃ¡n los tokens mÃ¡s frecuentes, manteniendo un lÃ­mite suficiente para esta tarea."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d5049aaf",
        "outputId": "53b8641d-df44-469b-a60d-8f4028e73a9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2729"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "token_counts = Counter()\n",
        "for row in dataset[\"train\"]:\n",
        "    token_counts.update(simple_tokenizer(row[\"text\"]))\n",
        "\n",
        "# Se reservan dos posiciones para [PAD] y [UNK]\n",
        "max_vocab_size = 10000\n",
        "most_common_tokens = [token for token, _ in token_counts.most_common(max_vocab_size - 2)]\n",
        "\n",
        "vocab = {\"[PAD]\": 0, \"[UNK]\": 1}\n",
        "for token in most_common_tokens:\n",
        "    vocab[token] = len(vocab)\n",
        "\n",
        "len(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiremos ahora la funciÃ³n que convertirÃ¡ cada texto en una secuencia de ids.\n",
        "\n",
        "Esta funciÃ³n harÃ¡ lo siguiente:\n",
        "- Tokenizar el texto\n",
        "- Traducir cada token a su id segÃºn el vocabulario\n",
        "- Reemplazar tokens desconocidos por [UNK]\n",
        "- Recortar si la secuencia excede max_len\n",
        "- Rellenar con [PAD] si la secuencia es mÃ¡s corta\n",
        "\n",
        "De esta forma, todas las entradas tendrÃ¡n una longitud fija y podrÃ¡n procesarse fÃ¡cilmente en lotes."
      ],
      "metadata": {
        "id": "PJ5m7l90Lp4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(text, max_length=max_len):\n",
        "    tokens = simple_tokenizer(text)\n",
        "    ids = [vocab.get(tok, vocab[\"[UNK]\"]) for tok in tokens[:max_length]]\n",
        "    ids += [vocab[\"[PAD]\"]] * (max_length - len(ids))\n",
        "    return ids"
      ],
      "metadata": {
        "id": "kKCl-EnUL_OI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Vocabulario: {len(vocab)} tokens\")\n",
        "\n",
        "print(\"\\nPrimeros 15 tokens del vocabulario construido (sin contar especiales):\")\n",
        "print(most_common_tokens[:15])\n",
        "\n",
        "mid = len(most_common_tokens) // 2\n",
        "print(\"\\n15 tokens de la mitad del vocabulario:\")\n",
        "print(most_common_tokens[mid:mid+15])\n",
        "\n",
        "print(\"\\nÃšltimos 15 tokens del vocabulario:\")\n",
        "print(most_common_tokens[-15:])"
      ],
      "metadata": {
        "id": "EzFv4eKvMEUo",
        "outputId": "e95e5028-d922-4df2-f244-b8f9791d5390",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario: 2729 tokens\n",
            "\n",
            "Primeros 15 tokens del vocabulario construido (sin contar especiales):\n",
            "['.', ',', 'de', 'y', 'la', 'el', 'en', 'muy', 'que', 'hotel', 'a', 'con', 'es', 'un', 'las']\n",
            "\n",
            "15 tokens de la mitad del vocabulario:\n",
            "['brares', 'grades', 'asiduo', 'vovere', 'murmullo', 'fuentes', 'restauraciÃ³n', 'lento', 'ojo', 'mes', 'mayo', 'grados', 'unicos', 'negÃ³', 'nevera']\n",
            "\n",
            "Ãšltimos 15 tokens del vocabulario:\n",
            "['victorio', 'lucchino', 'veÃ­a', 'divertÃ­', 'cafeteria', 'malas', 'cuidan', 'vi', 'mercure', 'costo', 'sabes', 'doonde', 'obstante', 'quizÃ¡s', '96']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenize_text(\"hola mundo\", max_length=8)\n",
        "tokenized"
      ],
      "metadata": {
        "id": "UmnBeYnaMKic",
        "outputId": "9f01790c-04ce-4e46-c7ca-ab8483979f9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[835, 252, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_2_token = {v: k for k, v in vocab.items()}\n",
        "[id_2_token[token_id] for token_id in tokenized]"
      ],
      "metadata": {
        "id": "5Y-tj39UMO83",
        "outputId": "1381f10d-91a6-45ac-ddac-6c721b360e27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hola', 'mundo', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ConclusiÃ³n de la construcciÃ³n del tokenizador\n",
        "\n",
        "El vocabulario obtenido es relativamente pequeÃ±o (2729 tokens), lo que favorece un entrenamiento mÃ¡s liviano y manejable.\n",
        "AdemÃ¡s, la exploraciÃ³n muestra que los tokens mÃ¡s frecuentes corresponden tanto a signos de puntuaciÃ³n como a palabras muy comunes del espaÃ±ol,\n",
        "lo cual es esperable en un enfoque de tokenizaciÃ³n simple.\n",
        "\n",
        "La prueba con una oraciÃ³n corta permitiÃ³ verificar que el proceso completo funciona correctamente:\n",
        "- cada palabra se convierte a un id,\n",
        "- las secuencias se recortan o rellenan segÃºn max_len,\n",
        "- y el padding se representa mediante el token especial [PAD].\n",
        "\n",
        "Con esto, ya se cuenta con un mecanismo funcional para transformar texto crudo en entradas numÃ©ricas listas para PyTorch."
      ],
      "metadata": {
        "id": "_Xngx3xDMrww"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c18e433"
      },
      "source": [
        "## Definiendo el dataset de pytorch\n",
        "\n",
        "Como ya se cuenta con:\n",
        "- un dataset cargado,\n",
        "- un tokenizador funcional,\n",
        "- un vocabulario,\n",
        "- y una longitud mÃ¡xima de secuencia,\n",
        "\n",
        "entonces ya es posible construir una clase Dataset que transforme cada ejemplo en tensores listos para el modelo.\n",
        "\n",
        "A diferencia del notebook original, en este caso no serÃ¡ necesario crear un split aleatorio, porque el dataset ya incluye particiones de entrenamiento, validaciÃ³n y prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ca70e65a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SpanishSentimentDataset(Dataset):\n",
        "    def __init__(self, hf_dataset_split, tokenizer, seq_length=48):\n",
        "        self.dataset = hf_dataset_split\n",
        "        self.tokenizer = tokenizer\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "        # En este dataset las etiquetas ya vienen como enteros (0 y 1)\n",
        "        self.num_classes = len(set(self.dataset[\"label\"]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = self.dataset[index][\"text\"]\n",
        "        y = self.dataset[index][\"label\"]\n",
        "\n",
        "        data = {\n",
        "            \"input_ids\": torch.tensor(\n",
        "                self.tokenizer(text, max_length=self.seq_length),\n",
        "                dtype=torch.long\n",
        "            ),\n",
        "            \"y\": torch.tensor(y, dtype=torch.long)\n",
        "        }\n",
        "        return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56de3493"
      },
      "source": [
        "Ahora se crearÃ¡n los datasets de entrenamiento, validaciÃ³n y prueba.\n",
        "\n",
        "Cada uno utilizarÃ¡:\n",
        "- el mismo tokenizador,\n",
        "- la misma longitud mÃ¡xima de secuencia,\n",
        "- y la misma estructura de salida.\n",
        "\n",
        "De esta forma, los tres conjuntos quedarÃ¡n listos para ser usados en dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "15200ea5",
        "outputId": "6de68815-2681-46c4-e8db-b1d493054e26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset: 1029\n",
            "Validation dataset: 147\n",
            "Test dataset: 296\n",
            "NÃºmero de clases: 2\n"
          ]
        }
      ],
      "source": [
        "train_dataset = SpanishSentimentDataset(dataset[\"train\"], tokenize_text, seq_length=max_len)\n",
        "val_dataset = SpanishSentimentDataset(dataset[\"validation\"], tokenize_text, seq_length=max_len)\n",
        "test_dataset = SpanishSentimentDataset(dataset[\"test\"], tokenize_text, seq_length=max_len)\n",
        "\n",
        "print(f\"Train dataset: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset: {len(val_dataset)}\")\n",
        "print(f\"Test dataset: {len(test_dataset)}\")\n",
        "print(f\"NÃºmero de clases: {train_dataset.num_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = train_dataset[0]\n",
        "\n",
        "print(\"Llaves del ejemplo:\", sample.keys())\n",
        "print(\"Shape de input_ids:\", sample[\"input_ids\"].shape)\n",
        "print(\"Etiqueta y:\", sample[\"y\"])\n",
        "print(\"Primeros 20 input_ids:\", sample[\"input_ids\"][:20])"
      ],
      "metadata": {
        "id": "fHMBYwQZNp9y",
        "outputId": "c25a2fd0-125b-43d8-f185-6dd8373168b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Llaves del ejemplo: dict_keys(['input_ids', 'y'])\n",
            "Shape de input_ids: torch.Size([48])\n",
            "Etiqueta y: tensor(1)\n",
            "Primeros 20 input_ids: tensor([  40,   57,    8,    7,   51,    4,    6,   64,    3,   13,   25,   19,\n",
            "         104,  706,   12,  273,  545,   35,    7, 1098])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(\"Dataloaders creados correctamente.\")"
      ],
      "metadata": {
        "id": "1jlASPZFNwya",
        "outputId": "9e14b0ca-6db3-46e4-9504-5f05ca30de06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataloaders creados correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))\n",
        "\n",
        "print(\"Shape de input_ids:\", batch[\"input_ids\"].shape)\n",
        "print(\"Shape de y:\", batch[\"y\"].shape)\n",
        "print(\"Primeras 5 etiquetas del batch:\", batch[\"y\"][:5])"
      ],
      "metadata": {
        "id": "w8sYm4WZN0hH",
        "outputId": "e47acf48-679e-4901-fa7a-1529ae0d9ab6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape de input_ids: torch.Size([32, 48])\n",
            "Shape de y: torch.Size([32])\n",
            "Primeras 5 etiquetas del batch: tensor([1, 0, 0, 0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------"
      ],
      "metadata": {
        "id": "FQ0UpdR1N2hp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "A84dn0UIN5hs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "611d4b0b"
      },
      "source": [
        "Y luego, procedemos a hacer el train-val-test split y crear los dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d7e9e1c"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 4 if not IN_COLAB else 12\n",
        "train_dataset, val_dataset, test_dataset = random_split(spanish_news_dataset, lengths=[0.8, 0.1, 0.1])\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ac44796"
      },
      "source": [
        "## DefiniciÃ³n del modelo LSTM\n",
        "\n",
        "Ahora vamos a configurar un mÃ³dulo pytorch simple para este problema. Vamos ha utilizar los embeddings, que vendrÃ­an siendo los vectores de palabra. Pytorch nos ofrece una capa con la que directamente podemos entrenarlos a partir de los token ids obtenidos. El resto consistirÃ¡ en invocar una capa LSTM seguida de una capa densa para la clasificaciÃ³n.\n",
        "\n",
        "Recordemos que las redes recurrentes como las LSTM por diseÃ±o enlazan todas las dimensiones del vector de entrada, formando asÃ­ la secuencia, la estructura natural que necesitamos representar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d38eb14b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTMBlock(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, num_layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, _) = self.lstm(embedded)\n",
        "        return hidden[-1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32f68240"
      },
      "source": [
        "### DefiniciÃ³n del clasificador\n",
        "\n",
        "Finalmente, definimos el modelo en si. Este modelo constarÃ¡ de 3 capas:\n",
        "\n",
        "- La tokenizaciÃ³n, tal como la definimos anteriormente.\n",
        "- El bloque LSTM, que acabamos de decinir.\n",
        "- Una capa densa adicional que servirÃ¡ como clasificador de aquello que nos entregue la capa del transformer.\n",
        "\n",
        "Como este es un LightningModule, aquÃ­ definiremos el resto de funciones utilitarias para el entrenamiento de la tarea."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d724f85",
        "outputId": "89bff272-1b8a-4407-92f1-5a6bbc0efea1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name       | Type               | Params | Mode \n",
            "----------------------------------------------------------\n",
            "0 | lstm       | LSTMBlock          | 13.1 M | train\n",
            "1 | classifier | Sequential         | 200 K  | train\n",
            "2 | train_acc  | MulticlassAccuracy | 0      | train\n",
            "3 | val_acc    | MulticlassAccuracy | 0      | train\n",
            "4 | test_acc   | MulticlassAccuracy | 0      | train\n",
            "----------------------------------------------------------\n",
            "13.3 M    Trainable params\n",
            "0         Non-trainable params\n",
            "13.3 M    Total params\n",
            "53.322    Total estimated model params size (MB)\n",
            "16        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2040/2040 [00:25<00:00, 79.38it/s, v_num=0, val-loss=0.525, val-acc=0.907, train-loss=0.0621, train-acc=0.985]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2040/2040 [00:26<00:00, 78.38it/s, v_num=0, val-loss=0.525, val-acc=0.907, train-loss=0.0621, train-acc=0.985]\n"
          ]
        }
      ],
      "source": [
        "from pytorch_lightning import LightningModule, Trainer\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "class SpanishNewsClassifierWithLSTM(LightningModule):\n",
        "\n",
        "    def __init__(self, vocab_size: int, num_classes: int, emb_dim: int, hidden_dim: int = 128):\n",
        "        super(SpanishNewsClassifierWithLSTM, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.lstm = LSTMBlock(vocab_size, emb_dim, hidden_dim, num_classes)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(hidden_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, num_classes),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "        self.train_acc = Accuracy(task='multiclass', num_classes=num_classes)\n",
        "        self.val_acc = Accuracy(task='multiclass', num_classes=num_classes)\n",
        "        self.test_acc = Accuracy(task='multiclass', num_classes=num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeddings = self.lstm(x)\n",
        "        return self.classifier(embeddings)\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch['input_ids'], batch['y']\n",
        "        # print(f\"\\nbatch-idx: {batch_idx}\")\n",
        "        # print(f\"shape of x: {x.shape}\")\n",
        "        # print(torch.max(x, dim=0))\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        self.train_acc(y_hat, y)\n",
        "        self.log('train-loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log('train-acc', self.train_acc, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        x, y = batch['input_ids'], batch['y']\n",
        "        y_hat = self(x)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        self.val_acc(y_hat, y)\n",
        "        self.log('val-loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log('val-acc', self.val_acc, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        x, y = batch['input_ids'], batch['y']\n",
        "        y_hat = self(x)\n",
        "        self.test_acc(y_hat, y)\n",
        "        self.log('test-acc', self.test_acc, prog_bar=True, on_step=False, on_epoch=True)\n",
        "\n",
        "\n",
        "    def predict_step(self, batch):\n",
        "        x = batch['input_ids']\n",
        "        return self(x)\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer =  torch.optim.AdamW(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "        return optimizer\n",
        "\n",
        "\n",
        "model = SpanishNewsClassifierWithLSTM(vocab_size=len(vocab) + 1, num_classes=spanish_news_dataset.num_classes, emb_dim=256)\n",
        "\n",
        "tb_logger = TensorBoardLogger('tb_logs', name='LSTMClassifier')\n",
        "callbacks=[EarlyStopping(monitor='train-loss', patience=3, mode='min')]\n",
        "trainer = Trainer(max_epochs=10, devices=1, logger=tb_logger, callbacks=callbacks, precision=\"16-mixed\")\n",
        "\n",
        "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7312d7c"
      },
      "source": [
        "Observemos el proceso de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65f9b20e"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e6dc01e",
        "outputId": "77152019-b732-4e6d-86dd-6340bfb45617"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-42fd403edfc8a0e6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-42fd403edfc8a0e6\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir tb_logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5dd09d6"
      },
      "source": [
        "Y como es de esperarse, realizaremos la validaciÃ³n contra el conjunto de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5d52f43",
        "outputId": "285d56dc-bcb7-4c5a-bba9-5dea15dedd77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 255/255 [00:01<00:00, 237.12it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\">        Test metric        </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test-acc          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.9029411673545837     </span>â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚\u001b[36m \u001b[0m\u001b[36m        test-acc         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.9029411673545837    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'test-acc': 0.9029411673545837}]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()\n",
        "trainer.test(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad06d232"
      },
      "source": [
        "### Haciendo predicciones\n",
        "\n",
        "Finalmente, vamos a hacer uso del modelo y ver que tan bueno es para la clasificaciÃ³n de noticias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff1c989e",
        "outputId": "f56c27fb-b23a-44b9-c43b-4ed13f1f485d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 255/255 [00:01<00:00, 219.44it/s]\n"
          ]
        }
      ],
      "source": [
        "predictions = trainer.predict(model, test_loader)\n",
        "predictions = torch.cat(predictions, dim=0)\n",
        "predictions = torch.argmax(predictions, dim=-1)\n",
        "predictions = [spanish_news_dataset.id_2_class_map[pred] for pred in predictions.numpy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bdacb5c",
        "outputId": "9dd34262-8bbf-4d69-9cde-5c985bfd0fa1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tokens_string</th>\n",
              "      <th>categorÃ­a</th>\n",
              "      <th>predicciÃ³n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6734</th>\n",
              "      <td>El Gobierno tiene un plan alternativo para ase...</td>\n",
              "      <td>[5, 3270, 1058, 102, 1737, 4007, 240, 834, 10,...</td>\n",
              "      <td>el gobierno tiene un plan alternativo para ase...</td>\n",
              "      <td>politics</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1905</th>\n",
              "      <td>Prevalencia de hipotiroidismo subclÃ­nico y su ...</td>\n",
              "      <td>[34012, 12, 1, 1, 36, 46, 703, 58, 1, 36, 1652...</td>\n",
              "      <td>prevalencia de [UNK] [UNK] y su relaciÃ³n con [...</td>\n",
              "      <td>medicine</td>\n",
              "      <td>medicine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3049</th>\n",
              "      <td>El Sol, la fuente inagotable de energÃ­a que da...</td>\n",
              "      <td>[5, 14608, 14, 2248, 10396, 12, 2641, 10, 246,...</td>\n",
              "      <td>el sol la fuente inagotable de energÃ­a que da ...</td>\n",
              "      <td>astronomy</td>\n",
              "      <td>astronomy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1772</th>\n",
              "      <td>Mondor en la mama. A propÃ³sito de un casoLa en...</td>\n",
              "      <td>[1, 54, 14, 1, 40, 554, 12, 102, 1, 1652, 12, ...</td>\n",
              "      <td>[UNK] en la [UNK] a propÃ³sito de un [UNK] enfe...</td>\n",
              "      <td>medicine</td>\n",
              "      <td>medicine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6980</th>\n",
              "      <td>Navantia acaba de firmar con la Marina de Noru...</td>\n",
              "      <td>[1, 11, 12, 23970, 58, 14, 27045, 12, 27768, 1...</td>\n",
              "      <td>[UNK] acaba de firmar con la marina de noruega...</td>\n",
              "      <td>military</td>\n",
              "      <td>military</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1589</th>\n",
              "      <td>Tienen una funciÃ³n parecida a los relojes o la...</td>\n",
              "      <td>[440, 19, 2427, 14721, 40, 34, 14066, 96, 77, ...</td>\n",
              "      <td>tienen una funciÃ³n parecida a los relojes o la...</td>\n",
              "      <td>tech</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>En Ãºltima instancia, cuando se apagan las luce...</td>\n",
              "      <td>[54, 1177, 5104, 206, 17, 16158, 77, 3867, 12,...</td>\n",
              "      <td>en Ãºltima instancia cuando se apagan las luces...</td>\n",
              "      <td>play</td>\n",
              "      <td>play</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7356</th>\n",
              "      <td>La compaÃ±Ã­a francesa Escape International ha p...</td>\n",
              "      <td>[14, 1151, 2772, 7008, 29665, 260, 1048, 54, 1...</td>\n",
              "      <td>la compaÃ±Ã­a francesa escape international ha p...</td>\n",
              "      <td>military</td>\n",
              "      <td>military</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6763</th>\n",
              "      <td>El Gobierno busca que Bruselas apruebe un impu...</td>\n",
              "      <td>[5, 3270, 232, 10, 14032, 36279, 102, 15003, 2...</td>\n",
              "      <td>el gobierno busca que bruselas apruebe un impu...</td>\n",
              "      <td>politics</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3341</th>\n",
              "      <td>comentarios 44Cybertron, el planeta de losÂ Tra...</td>\n",
              "      <td>[7493, 1, 5, 3124, 12, 34, 8114, 5, 29619, 12,...</td>\n",
              "      <td>comentarios [UNK] el planeta de los transforme...</td>\n",
              "      <td>astronomy</td>\n",
              "      <td>astronomy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7826</th>\n",
              "      <td>La palabra bienquerencia es poco usada, pero e...</td>\n",
              "      <td>[14, 203, 1, 4, 610, 32326, 403, 198, 11659, 2...</td>\n",
              "      <td>la palabra [UNK] es poco usada pero existe ind...</td>\n",
              "      <td>religion</td>\n",
              "      <td>religion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8578</th>\n",
              "      <td>Segunda victoria en el WRC para el finlandÃ©s E...</td>\n",
              "      <td>[1090, 3982, 54, 5, 1, 240, 5, 19053, 1, 1, 10...</td>\n",
              "      <td>segunda victoria en el [UNK] para el finlandÃ©s...</td>\n",
              "      <td>motor</td>\n",
              "      <td>motor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3456</th>\n",
              "      <td>No hay un equipo mÃ¡s desgraciado que el AlmerÃ­...</td>\n",
              "      <td>[196, 124, 102, 4877, 130, 20027, 10, 5, 23674...</td>\n",
              "      <td>no hay un equipo mÃ¡s desgraciado que el almerÃ­...</td>\n",
              "      <td>sport</td>\n",
              "      <td>sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5659</th>\n",
              "      <td>MÃ¡s allÃ¡ de las cÃ¡psulas de cafÃ© hay un mundo ...</td>\n",
              "      <td>[130, 219, 12, 77, 32819, 12, 10027, 124, 102,...</td>\n",
              "      <td>mÃ¡s allÃ¡ de las cÃ¡psulas de cafÃ© hay un mundo ...</td>\n",
              "      <td>alimentation</td>\n",
              "      <td>alimentation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2184</th>\n",
              "      <td>Evolucion de la vida sexual de la mujer. Fisio...</td>\n",
              "      <td>[1, 12, 14, 195, 7773, 12, 14, 749, 1, 12, 14,...</td>\n",
              "      <td>[UNK] de la vida sexual de la mujer [UNK] de l...</td>\n",
              "      <td>medicine</td>\n",
              "      <td>medicine</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto  \\\n",
              "6734  El Gobierno tiene un plan alternativo para ase...   \n",
              "1905  Prevalencia de hipotiroidismo subclÃ­nico y su ...   \n",
              "3049  El Sol, la fuente inagotable de energÃ­a que da...   \n",
              "1772  Mondor en la mama. A propÃ³sito de un casoLa en...   \n",
              "6980  Navantia acaba de firmar con la Marina de Noru...   \n",
              "1589  Tienen una funciÃ³n parecida a los relojes o la...   \n",
              "240   En Ãºltima instancia, cuando se apagan las luce...   \n",
              "7356  La compaÃ±Ã­a francesa Escape International ha p...   \n",
              "6763  El Gobierno busca que Bruselas apruebe un impu...   \n",
              "3341  comentarios 44Cybertron, el planeta de losÂ Tra...   \n",
              "7826  La palabra bienquerencia es poco usada, pero e...   \n",
              "8578  Segunda victoria en el WRC para el finlandÃ©s E...   \n",
              "3456  No hay un equipo mÃ¡s desgraciado que el AlmerÃ­...   \n",
              "5659  MÃ¡s allÃ¡ de las cÃ¡psulas de cafÃ© hay un mundo ...   \n",
              "2184  Evolucion de la vida sexual de la mujer. Fisio...   \n",
              "\n",
              "                                                 tokens  \\\n",
              "6734  [5, 3270, 1058, 102, 1737, 4007, 240, 834, 10,...   \n",
              "1905  [34012, 12, 1, 1, 36, 46, 703, 58, 1, 36, 1652...   \n",
              "3049  [5, 14608, 14, 2248, 10396, 12, 2641, 10, 246,...   \n",
              "1772  [1, 54, 14, 1, 40, 554, 12, 102, 1, 1652, 12, ...   \n",
              "6980  [1, 11, 12, 23970, 58, 14, 27045, 12, 27768, 1...   \n",
              "1589  [440, 19, 2427, 14721, 40, 34, 14066, 96, 77, ...   \n",
              "240   [54, 1177, 5104, 206, 17, 16158, 77, 3867, 12,...   \n",
              "7356  [14, 1151, 2772, 7008, 29665, 260, 1048, 54, 1...   \n",
              "6763  [5, 3270, 232, 10, 14032, 36279, 102, 15003, 2...   \n",
              "3341  [7493, 1, 5, 3124, 12, 34, 8114, 5, 29619, 12,...   \n",
              "7826  [14, 203, 1, 4, 610, 32326, 403, 198, 11659, 2...   \n",
              "8578  [1090, 3982, 54, 5, 1, 240, 5, 19053, 1, 1, 10...   \n",
              "3456  [196, 124, 102, 4877, 130, 20027, 10, 5, 23674...   \n",
              "5659  [130, 219, 12, 77, 32819, 12, 10027, 124, 102,...   \n",
              "2184  [1, 12, 14, 195, 7773, 12, 14, 749, 1, 12, 14,...   \n",
              "\n",
              "                                          tokens_string     categorÃ­a  \\\n",
              "6734  el gobierno tiene un plan alternativo para ase...      politics   \n",
              "1905  prevalencia de [UNK] [UNK] y su relaciÃ³n con [...      medicine   \n",
              "3049  el sol la fuente inagotable de energÃ­a que da ...     astronomy   \n",
              "1772  [UNK] en la [UNK] a propÃ³sito de un [UNK] enfe...      medicine   \n",
              "6980  [UNK] acaba de firmar con la marina de noruega...      military   \n",
              "1589  tienen una funciÃ³n parecida a los relojes o la...          tech   \n",
              "240   en Ãºltima instancia cuando se apagan las luces...          play   \n",
              "7356  la compaÃ±Ã­a francesa escape international ha p...      military   \n",
              "6763  el gobierno busca que bruselas apruebe un impu...      politics   \n",
              "3341  comentarios [UNK] el planeta de los transforme...     astronomy   \n",
              "7826  la palabra [UNK] es poco usada pero existe ind...      religion   \n",
              "8578  segunda victoria en el [UNK] para el finlandÃ©s...         motor   \n",
              "3456  no hay un equipo mÃ¡s desgraciado que el almerÃ­...         sport   \n",
              "5659  mÃ¡s allÃ¡ de las cÃ¡psulas de cafÃ© hay un mundo ...  alimentation   \n",
              "2184  [UNK] de la vida sexual de la mujer [UNK] de l...      medicine   \n",
              "\n",
              "        predicciÃ³n  \n",
              "6734      politics  \n",
              "1905      medicine  \n",
              "3049     astronomy  \n",
              "1772      medicine  \n",
              "6980      military  \n",
              "1589          tech  \n",
              "240           play  \n",
              "7356      military  \n",
              "6763      politics  \n",
              "3341     astronomy  \n",
              "7826      religion  \n",
              "8578         motor  \n",
              "3456         sport  \n",
              "5659  alimentation  \n",
              "2184      medicine  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_indices = test_dataset.indices\n",
        "df = pd.DataFrame(data={\n",
        "    \"texto\": dataset[test_indices]['text'],\n",
        "    \"tokens\": [tokenize_text(v) for v in dataset[test_indices]['text']],\n",
        "    \"categorÃ­a\": dataset[test_indices]['category'],\n",
        "    'predicciÃ³n': predictions\n",
        "}, index=test_indices)\n",
        "\n",
        "df['tokens_string'] = df.tokens.apply(lambda t: ' '.join([id_2_token[i] for i in t]))\n",
        "df = df[[\"texto\", \"tokens\", \"tokens_string\", \"categorÃ­a\", \"predicciÃ³n\"]]\n",
        "df.style.set_table_styles(\n",
        "    [\n",
        "        {'selector': 'td', 'props': [('word-wrap', 'break-word')]}\n",
        "    ]\n",
        ")\n",
        "df.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c5085d5",
        "outputId": "1220e96c-01c3-43d9-d9ce-45b3cc81d98e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tokens_string</th>\n",
              "      <th>categorÃ­a</th>\n",
              "      <th>predicciÃ³n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1120</th>\n",
              "      <td>Pues parece que la policÃ­a holandesa se precip...</td>\n",
              "      <td>[2020, 491, 10, 14, 1497, 38011, 17, 38012, 10...</td>\n",
              "      <td>pues parece que la policÃ­a holandesa se precip...</td>\n",
              "      <td>tech</td>\n",
              "      <td>play</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7473</th>\n",
              "      <td>El nuevo Consejo de AdministraciÃ³n deÂ Fincanti...</td>\n",
              "      <td>[5, 8, 17379, 12, 444, 12, 1, 1, 29649, 45, 14...</td>\n",
              "      <td>el nuevo consejo de administraciÃ³n de [UNK] [U...</td>\n",
              "      <td>military</td>\n",
              "      <td>economy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2765</th>\n",
              "      <td>Fuente de la imagen, OtherJune Williams creciÃ³...</td>\n",
              "      <td>[2248, 12, 14, 564, 1, 10953, 5680, 57, 40, 34...</td>\n",
              "      <td>fuente de la imagen [UNK] williams creciÃ³ junt...</td>\n",
              "      <td>astronomy</td>\n",
              "      <td>religion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4142</th>\n",
              "      <td>El Elche espera a Ã“scar Plano. El delantero ma...</td>\n",
              "      <td>[5, 36649, 4040, 40, 2947, 1846, 5, 1, 8710, 3...</td>\n",
              "      <td>el elche espera a Ã³scar plano el [UNK] madrile...</td>\n",
              "      <td>sport</td>\n",
              "      <td>economy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>Algunos de los monumentos mÃ¡s famosos del Rein...</td>\n",
              "      <td>[501, 12, 34, 23928, 130, 1018, 7, 2125, 8269,...</td>\n",
              "      <td>algunos de los monumentos mÃ¡s famosos del rein...</td>\n",
              "      <td>play</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5835</th>\n",
              "      <td>Hay anuncios que irremediablemente se quedan a...</td>\n",
              "      <td>[124, 11554, 10, 12505, 17, 1895, 12251, 54, 2...</td>\n",
              "      <td>hay anuncios que irremediablemente se quedan a...</td>\n",
              "      <td>alimentation</td>\n",
              "      <td>astronomy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7368</th>\n",
              "      <td>Navantia junto a otras 5 grandes empresas, Rep...</td>\n",
              "      <td>[1, 57, 40, 2255, 901, 8594, 1, 1, 14784, 3176...</td>\n",
              "      <td>[UNK] junto a otras grandes empresas [UNK] [UN...</td>\n",
              "      <td>military</td>\n",
              "      <td>motor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9001</th>\n",
              "      <td>La versiÃ³n mÃ¡s accesible del Lucid Air llega p...</td>\n",
              "      <td>[14, 2049, 130, 14266, 7, 1, 7550, 333, 45, 31...</td>\n",
              "      <td>la versiÃ³n mÃ¡s accesible del [UNK] air llega p...</td>\n",
              "      <td>motor</td>\n",
              "      <td>economy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7846</th>\n",
              "      <td>Pedro SÃ¡nchez ha regalado toda una ley de adoc...</td>\n",
              "      <td>[399, 9554, 260, 19502, 89, 19, 2565, 12, 1, 5...</td>\n",
              "      <td>pedro sÃ¡nchez ha regalado toda una ley de [UNK...</td>\n",
              "      <td>religion</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8103</th>\n",
              "      <td>Es algo que estÃ¡ sorprendiendo en la red. Mill...</td>\n",
              "      <td>[4, 559, 10, 482, 24341, 54, 14, 1063, 1059, 1...</td>\n",
              "      <td>es algo que estÃ¡ sorprendiendo en la red millo...</td>\n",
              "      <td>religion</td>\n",
              "      <td>astronomy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9900</th>\n",
              "      <td>La Edad Media no fue la Ã©poca maloliente y suc...</td>\n",
              "      <td>[14, 7466, 4151, 196, 395, 14, 1629, 1, 36, 47...</td>\n",
              "      <td>la edad media no fue la Ã©poca [UNK] y sucia qu...</td>\n",
              "      <td>economy</td>\n",
              "      <td>astronomy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>786</th>\n",
              "      <td>La Ãºltima generaciÃ³n de videoconsolas lanzadas...</td>\n",
              "      <td>[14, 1177, 2224, 12, 30807, 21743, 269, 1481, ...</td>\n",
              "      <td>la Ãºltima generaciÃ³n de videoconsolas lanzadas...</td>\n",
              "      <td>play</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9576</th>\n",
              "      <td>La necesidad de energÃ­a estÃ¡ presente en prÃ¡ct...</td>\n",
              "      <td>[14, 2497, 12, 2641, 482, 388, 54, 4057, 201, ...</td>\n",
              "      <td>la necesidad de energÃ­a estÃ¡ presente en prÃ¡ct...</td>\n",
              "      <td>economy</td>\n",
              "      <td>fashion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2098</th>\n",
              "      <td>Â¿QuÃ© es la farmacologÃ­a? Ciencia que estudia l...</td>\n",
              "      <td>[1183, 4, 14, 1, 4182, 10, 38159, 34, 11561, 1...</td>\n",
              "      <td>quÃ© es la [UNK] ciencia que estudia los fÃ¡rmac...</td>\n",
              "      <td>medicine</td>\n",
              "      <td>military</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7888</th>\n",
              "      <td>El Ayuntamiento de Palma ha colocado este mart...</td>\n",
              "      <td>[5, 4852, 12, 9239, 260, 15095, 55, 9247, 14, ...</td>\n",
              "      <td>el ayuntamiento de palma ha colocado este mart...</td>\n",
              "      <td>religion</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto  \\\n",
              "1120  Pues parece que la policÃ­a holandesa se precip...   \n",
              "7473  El nuevo Consejo de AdministraciÃ³n deÂ Fincanti...   \n",
              "2765  Fuente de la imagen, OtherJune Williams creciÃ³...   \n",
              "4142  El Elche espera a Ã“scar Plano. El delantero ma...   \n",
              "689   Algunos de los monumentos mÃ¡s famosos del Rein...   \n",
              "5835  Hay anuncios que irremediablemente se quedan a...   \n",
              "7368  Navantia junto a otras 5 grandes empresas, Rep...   \n",
              "9001  La versiÃ³n mÃ¡s accesible del Lucid Air llega p...   \n",
              "7846  Pedro SÃ¡nchez ha regalado toda una ley de adoc...   \n",
              "8103  Es algo que estÃ¡ sorprendiendo en la red. Mill...   \n",
              "9900  La Edad Media no fue la Ã©poca maloliente y suc...   \n",
              "786   La Ãºltima generaciÃ³n de videoconsolas lanzadas...   \n",
              "9576  La necesidad de energÃ­a estÃ¡ presente en prÃ¡ct...   \n",
              "2098  Â¿QuÃ© es la farmacologÃ­a? Ciencia que estudia l...   \n",
              "7888  El Ayuntamiento de Palma ha colocado este mart...   \n",
              "\n",
              "                                                 tokens  \\\n",
              "1120  [2020, 491, 10, 14, 1497, 38011, 17, 38012, 10...   \n",
              "7473  [5, 8, 17379, 12, 444, 12, 1, 1, 29649, 45, 14...   \n",
              "2765  [2248, 12, 14, 564, 1, 10953, 5680, 57, 40, 34...   \n",
              "4142  [5, 36649, 4040, 40, 2947, 1846, 5, 1, 8710, 3...   \n",
              "689   [501, 12, 34, 23928, 130, 1018, 7, 2125, 8269,...   \n",
              "5835  [124, 11554, 10, 12505, 17, 1895, 12251, 54, 2...   \n",
              "7368  [1, 57, 40, 2255, 901, 8594, 1, 1, 14784, 3176...   \n",
              "9001  [14, 2049, 130, 14266, 7, 1, 7550, 333, 45, 31...   \n",
              "7846  [399, 9554, 260, 19502, 89, 19, 2565, 12, 1, 5...   \n",
              "8103  [4, 559, 10, 482, 24341, 54, 14, 1063, 1059, 1...   \n",
              "9900  [14, 7466, 4151, 196, 395, 14, 1629, 1, 36, 47...   \n",
              "786   [14, 1177, 2224, 12, 30807, 21743, 269, 1481, ...   \n",
              "9576  [14, 2497, 12, 2641, 482, 388, 54, 4057, 201, ...   \n",
              "2098  [1183, 4, 14, 1, 4182, 10, 38159, 34, 11561, 1...   \n",
              "7888  [5, 4852, 12, 9239, 260, 15095, 55, 9247, 14, ...   \n",
              "\n",
              "                                          tokens_string     categorÃ­a  \\\n",
              "1120  pues parece que la policÃ­a holandesa se precip...          tech   \n",
              "7473  el nuevo consejo de administraciÃ³n de [UNK] [U...      military   \n",
              "2765  fuente de la imagen [UNK] williams creciÃ³ junt...     astronomy   \n",
              "4142  el elche espera a Ã³scar plano el [UNK] madrile...         sport   \n",
              "689   algunos de los monumentos mÃ¡s famosos del rein...          play   \n",
              "5835  hay anuncios que irremediablemente se quedan a...  alimentation   \n",
              "7368  [UNK] junto a otras grandes empresas [UNK] [UN...      military   \n",
              "9001  la versiÃ³n mÃ¡s accesible del [UNK] air llega p...         motor   \n",
              "7846  pedro sÃ¡nchez ha regalado toda una ley de [UNK...      religion   \n",
              "8103  es algo que estÃ¡ sorprendiendo en la red millo...      religion   \n",
              "9900  la edad media no fue la Ã©poca [UNK] y sucia qu...       economy   \n",
              "786   la Ãºltima generaciÃ³n de videoconsolas lanzadas...          play   \n",
              "9576  la necesidad de energÃ­a estÃ¡ presente en prÃ¡ct...       economy   \n",
              "2098  quÃ© es la [UNK] ciencia que estudia los fÃ¡rmac...      medicine   \n",
              "7888  el ayuntamiento de palma ha colocado este mart...      religion   \n",
              "\n",
              "     predicciÃ³n  \n",
              "1120       play  \n",
              "7473    economy  \n",
              "2765   religion  \n",
              "4142    economy  \n",
              "689        tech  \n",
              "5835  astronomy  \n",
              "7368      motor  \n",
              "9001    economy  \n",
              "7846   politics  \n",
              "8103  astronomy  \n",
              "9900  astronomy  \n",
              "786        tech  \n",
              "9576    fashion  \n",
              "2098   military  \n",
              "7888   politics  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "errors = df[df['categorÃ­a'] != df['predicciÃ³n']]\n",
        "errors.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88103e5e"
      },
      "source": [
        "## Conclusiones\n",
        "\n",
        "- En este caso tenemos una tarea de clasificaciÃ³n de texto de mÃºltiples clases.\n",
        "- Estamos usando un bloque LSTM como featurizer, es decir lo usamos para extraer features de las secuencias de entrada con las cuales harÃ©mos predicciones luego.\n",
        "- NÃ³tese que de las capas LSTM, solo nos interesa la Ãºltima, ya que esta recupera todas las operaciones enalazadas anteriores.\n",
        "- Observamos que el modelo toma su tiempo en entrenar, esto es natural debido al diseÃ±o de las LSTM, donde por cada paso de tiempo se debe computar un gradiente, por lo que el computo es mucho mayor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e73526f"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
